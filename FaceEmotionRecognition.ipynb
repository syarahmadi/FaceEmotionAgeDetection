{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"FaceEmotionRecognition.ipynb","provenance":[],"authorship_tag":"ABX9TyP29uTNstpGbim42jnjuc0r"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive/')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A4HMMNyXkdLF","executionInfo":{"status":"ok","timestamp":1653279751622,"user_tz":240,"elapsed":900,"user":{"displayName":"Somayeh Yarahmadi","userId":"10947969451817703509"}},"outputId":"2f625b68-182b-4c93-dede-4f7587b57179"},"execution_count":45,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"]}]},{"cell_type":"code","execution_count":46,"metadata":{"id":"AMz4Aj1Z4Ke5","executionInfo":{"status":"ok","timestamp":1653279751623,"user_tz":240,"elapsed":3,"user":{"displayName":"Somayeh Yarahmadi","userId":"10947969451817703509"}}},"outputs":[],"source":["from tensorflow import keras\n","from keras.models import Sequential \n","import cv2\n","import os\n","from pathlib import Path\n","# import face_recognition\n","import pandas as pd\n","import tensorflow as tf\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import tensorflow as tf\n","from skimage import io\n","import glob\n","import random\n","from sklearn.model_selection import train_test_split\n","\n"]},{"cell_type":"code","source":["from operator import concat\n","#Define Paths\n","data_train_path = Path('/content/drive/My Drive/data/FaceData/train')         # Define path for data\n","data_test_path = Path('/content/drive/My Drive/data/FaceData/test')         # Define path for data\n","\n","\n","def path_produce(premiere_path,emotion_path):\n","  y = premiere_path/emotion_path\n","  return y\n","emotion = [\"angry\", \"disgusted\", \"fearful\", \"happy\",\"neutral\", \"sad\", \"suprised\"]\n","emotion_number = [\"0\", \"1\", \"2\", \"3\",\"4\", \"5\", \"6\"]\n","# emotion_path = [\"angry_train_path\", \"disgusted_train_path\", \"fearful_train_path\", \"happy_train_path\", \"neutral_train_path\", \"sad_train_path\", \"suprised_train_path\"]\n","\n","\n","def get_images(images_path): \n","  return images_path.glob('*.png')\n","\n","# all_train_data = pd.DataFrame(columns=['image' , 'class'],index=None)\n","# all_test_data  = pd.DataFrame(columns=['image' , 'class'],index=None)\n","\n","\n","\n","def get_path_give_images(path,emotion,emotion_number):\n","  all_data = pd.DataFrame(columns=['image' , 'emotionclass'],index=None)\n","  j=0;\n","  for i in emotion:\n","    EmPath = path_produce(path, i)\n","    array_images  = get_images(EmPath) \n","    data = pd.DataFrame(array_images, columns=['image'],index=None)\n","    data['emotionclass'] = emotion_number[j]\n","    j+=1\n","    d=[all_data,data]\n","    all_data = pd.concat(d)\n","  return all_data\n","\n","all_train_data = get_path_give_images(data_train_path,emotion,emotion_number)\n","all_test_data = get_path_give_images(data_test_path,emotion,emotion_number)\n","\n","train_data = all_train_data.sample(frac=1.).reset_index(drop=True)\n","test_data = all_test_data.sample(frac=1.).reset_index(drop=True)\n","\n","X = train_data.image;\n","y = train_data.emotionclass;\n","\n","\n","X_val, X_train, y_val , y_train = train_test_split(X, y, test_size=0.9, random_state=1)\n","df1 = {'image': X_train, 'emotionclass': y_train}\n","train_data = pd.DataFrame(df1,index=None)\n","\n","df2 = {'image': X_val, 'emotionclass': y_val}\n","validation_data = pd.DataFrame(df2,index=None)\n","\n"],"metadata":{"id":"V2L0bgBhdOSI","executionInfo":{"status":"ok","timestamp":1653279882850,"user_tz":240,"elapsed":131229,"user":{"displayName":"Somayeh Yarahmadi","userId":"10947969451817703509"}},"colab":{"base_uri":"https://localhost:8080/","height":222},"outputId":"54efd219-6d4b-4b25-a66c-6efddaf038e7"},"execution_count":47,"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]},{"output_type":"stream","name":"stderr","text":["Exception ignored in: 'zmq.backend.cython.message.Frame.__dealloc__'\n","Traceback (most recent call last):\n","  File \"zmq/backend/cython/checkrc.pxd\", line 13, in zmq.backend.cython.checkrc._check_rc\n","KeyboardInterrupt\n"]}]},{"cell_type":"code","source":["validation_data.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"AN4T8ZP8EufF","executionInfo":{"status":"ok","timestamp":1653279882850,"user_tz":240,"elapsed":8,"user":{"displayName":"Somayeh Yarahmadi","userId":"10947969451817703509"}},"outputId":"9c6b1750-ce84-45f4-9663-71527b14c525"},"execution_count":48,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                   image emotionclass\n","2148   /content/drive/My Drive/data/FaceData/train/ha...            3\n","11128  /content/drive/My Drive/data/FaceData/train/ha...            3\n","1212   /content/drive/My Drive/data/FaceData/train/ha...            3\n","16303  /content/drive/My Drive/data/FaceData/train/ne...            4\n","25123  /content/drive/My Drive/data/FaceData/train/ne...            4"],"text/html":["\n","  <div id=\"df-608bfb51-26f8-469e-abee-565d9ebd571e\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>image</th>\n","      <th>emotionclass</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2148</th>\n","      <td>/content/drive/My Drive/data/FaceData/train/ha...</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>11128</th>\n","      <td>/content/drive/My Drive/data/FaceData/train/ha...</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>1212</th>\n","      <td>/content/drive/My Drive/data/FaceData/train/ha...</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>16303</th>\n","      <td>/content/drive/My Drive/data/FaceData/train/ne...</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>25123</th>\n","      <td>/content/drive/My Drive/data/FaceData/train/ne...</td>\n","      <td>4</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-608bfb51-26f8-469e-abee-565d9ebd571e')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-608bfb51-26f8-469e-abee-565d9ebd571e button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-608bfb51-26f8-469e-abee-565d9ebd571e');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":48}]},{"cell_type":"code","source":["# # plot intensity of pixels of 5 images\n","# for i in range(3):\n","#   plt.xlabel(\"Pixel values\")\n","#   plt.ylabel(\"Intensity distribution of an image\")\n","#   plt.title(\"Image{}\".format(i+1))\n","#   a = train_data['image'].iloc[i]\n","#   img = io.imread(a,1)\n","#   plt.hist(img.ravel())\n","#   plt.show()"],"metadata":{"id":"U8pDDRmouWdb","executionInfo":{"status":"ok","timestamp":1653279882851,"user_tz":240,"elapsed":6,"user":{"displayName":"Somayeh Yarahmadi","userId":"10947969451817703509"}}},"execution_count":49,"outputs":[]},{"cell_type":"code","source":["# Parameters\n","IMG_SIZE = 256  # Image size\n","BATCH_SIZE = 64\n","\n","# Preprocessing object\n","idg = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1/255.0)\n","\n","# Turn values to strings as a requirement for flow_from_dataframe\n","train_data['image'] = train_data['image'].astype(\"string\")\n","validation_data['image'] = validation_data['image'].astype(\"string\")\n","test_data['image'] = test_data['image'].astype(\"string\")\n","\n","# Create train generator\n","train_gen = idg.flow_from_dataframe(dataframe= train_data,\n","                                         x_col = 'image',\n","                                         y_col = 'emotionclass',\n","                                         target_size = (48,48),\n","                                         class_mode = 'categorical',\n","                                         color_mode = 'grayscale',\n","                                         batch_size = BATCH_SIZE,\n","                                         )\n","\n","# Create test generator\n","validation_gen = idg.flow_from_dataframe(dataframe= validation_data, \n","                                         x_col = 'image',\n","                                         y_col = 'emotionclass',\n","                                         target_size = (48,48),\n","                                         class_mode = 'categorical',\n","                                         color_mode = 'grayscale',\n","                                         batch_size = BATCH_SIZE,\n","                                         )\n","# Create test generator\n","test_gen = idg.flow_from_dataframe(dataframe= test_data, \n","                                         x_col = 'image',\n","                                         y_col = 'emotionclass',\n","                                         target_size = (48,48),\n","                                         class_mode = 'categorical',\n","                                         color_mode = 'grayscale',\n","                                         batch_size = BATCH_SIZE,\n","                                         )"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hZKdCD-Vq0uQ","executionInfo":{"status":"ok","timestamp":1653279891172,"user_tz":240,"elapsed":8326,"user":{"displayName":"Somayeh Yarahmadi","userId":"10947969451817703509"}},"outputId":"758836c2-616a-455e-848b-0280afaf1180"},"execution_count":50,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 22985 validated image filenames belonging to 6 classes.\n","Found 2553 validated image filenames belonging to 6 classes.\n","Found 6347 validated image filenames belonging to 6 classes.\n"]}]},{"cell_type":"code","source":["# # Parameters\n","# IMG_SIZE = 256  # Image size\n","# BATCH_SIZE = 16\n","\n","# # Preprocessing object\n","# idg = tf.keras.preprocessing.image.ImageDataGenerator(\n","#     featurewise_center=False, samplewise_center=False,\n","#     featurewise_std_normalization=False, samplewise_std_normalization=False,\n","#     zca_whitening=False, zca_epsilon=1e-06, rotation_range=10, width_shift_range=0.1,\n","#     height_shift_range=0.1, brightness_range=None, shear_range=0.1, zoom_range=0.1,\n","#     channel_shift_range=0.0, fill_mode='nearest', cval=0.0, horizontal_flip=True,\n","#     vertical_flip=True, rescale=1/255.0, preprocessing_function=None,\n","#     data_format=None, validation_split=0.0, dtype=None\n","# )\n","\n","# # Turn values to strings as a requirement for flow_from_dataframe\n","# train_data['image'] = train_data['image'].astype(\"string\")\n","# validation_data['image'] = validation_data['image'].astype(\"string\")\n","# test_data['image'] = test_data['image'].astype(\"string\")\n","\n","# # Create train generator\n","# train_gen = idg.flow_from_dataframe(dataframe= train_data,\n","#                                          directory=None, \n","#                                          x_col = 'image',\n","#                                          y_col = 'emotionclass',\n","#                                          class_mode = 'categorical',\n","#                                          color_mode = 'grayscale',\n","#                                          target_size = (IMG_SIZE,IMG_SIZE), \n","#                                          batch_size = BATCH_SIZE,\n","#                                          shuffle = True,\n","#                                          )\n","\n","# # Create test generator\n","# validation_gen = idg.flow_from_dataframe(dataframe= validation_data, \n","#                                          directory=None, \n","#                                          x_col = 'image',\n","#                                          y_col = 'emotionclass',\n","#                                          class_mode = 'sparse',\n","#                                          color_mode = 'grayscale',\n","#                                          target_size = (IMG_SIZE,IMG_SIZE), \n","#                                          batch_size = BATCH_SIZE,\n","#                                          shuffle = True,\n","\n","#                                          )\n","\n","# # Create test generator\n","# test_gen = idg.flow_from_dataframe(dataframe= test_data, \n","#                                          directory=None, \n","#                                          x_col = 'image',\n","#                                          y_col = 'emotionclass',\n","#                                          class_mode = 'categorical',\n","#                                          color_mode = 'grayscale',\n","#                                          target_size = (IMG_SIZE,IMG_SIZE), \n","#                                          batch_size = BATCH_SIZE,\n","#                                          shuffle = False,\n","#                                          )"],"metadata":{"id":"hHHjQhmJS2s7","executionInfo":{"status":"ok","timestamp":1653279891173,"user_tz":240,"elapsed":3,"user":{"displayName":"Somayeh Yarahmadi","userId":"10947969451817703509"}}},"execution_count":51,"outputs":[]},{"cell_type":"code","source":["from keras.models import Sequential\n","from keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, Flatten, BatchNormalization\n","import tensorflow as tf\n","\n","\n","emotion_model = Sequential()\n","\n","emotion_model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(48, 48, 1)))\n","emotion_model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n","emotion_model.add(MaxPooling2D(pool_size=(2, 2)))\n","emotion_model.add(Dropout(0.25))\n","\n","emotion_model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n","emotion_model.add(MaxPooling2D(pool_size=(2, 2)))\n","emotion_model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n","emotion_model.add(MaxPooling2D(pool_size=(2, 2)))\n","emotion_model.add(Dropout(0.25))\n","\n","emotion_model.add(Flatten())\n","emotion_model.add(Dense(1024, activation='relu'))\n","emotion_model.add(Dropout(0.5))\n","emotion_model.add(Dense(6, activation='softmax'))"],"metadata":{"id":"0ac6gbSOJXZv","executionInfo":{"status":"ok","timestamp":1653279891356,"user_tz":240,"elapsed":185,"user":{"displayName":"Somayeh Yarahmadi","userId":"10947969451817703509"}}},"execution_count":52,"outputs":[]},{"cell_type":"code","source":["emotion_model.compile(loss='categorical_crossentropy', optimizer = tf.keras.optimizers.Adam(lr=0.0001, decay=1e-6), metrics=['accuracy'])\n"],"metadata":{"id":"C6ggW_hj7IzA","executionInfo":{"status":"ok","timestamp":1653279891357,"user_tz":240,"elapsed":7,"user":{"displayName":"Somayeh Yarahmadi","userId":"10947969451817703509"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"170732e7-7246-464f-e540-053a40720fb5"},"execution_count":53,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  super(Adam, self).__init__(name, **kwargs)\n"]}]},{"cell_type":"code","source":["#Train Model\n","# from keras.models import load_model\n","\n","# TRAINING = True\n","NUM_EPOCHS = 20\n","# model_path = '/content/drive/MyDrive/Project_Colab/Pneumonia_detection/my_model.h5'\n","\n","# if TRAINING:\n","# emotion_model_info = emotion_model.fit_generator(train_gen, \n","#                                         epochs=NUM_EPOCHS, \n","#                                         steps_per_epoch=None,\n","#                                         validation_data=validation_gen,\n","#                                         validation_steps=len(validation_gen))\n","\n","emotion_model_info = emotion_model.fit_generator(\n","        train_gen,\n","        steps_per_epoch=len(train_gen) // 5,\n","        epochs=20,\n","        validation_data=validation_gen,\n","        validation_steps=len(validation_gen) // 5)\n","   \n","# else:\n","\n","  # returns a compiled model\n","  # identical to the previous one\n","  # model = load_model(model_path, compile=True)"],"metadata":{"id":"mvKwy-a67JLa","colab":{"base_uri":"https://localhost:8080/"},"outputId":"a8b63e6b-d9fc-4d65-a79f-0a447788c975"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:20: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","43/72 [================>.............] - ETA: 5:26 - loss: 1.6878 - accuracy: 0.2609"]}]},{"cell_type":"code","source":["#Train Model\n","from keras.models import load_model\n","\n","TRAINING = True\n","NUM_EPOCHS = 30\n","model_path = '/content/drive/MyDrive/Project_Colab/Pneumonia_detection/my_model.h5'\n","\n","if TRAINING:\n","  r =emotion_model.fit(train_gen, \n","                epochs=NUM_EPOCHS, \n","                validation_data=validation_gen,\n","                validation_steps=len(validation_gen),\n","                steps_per_epoch=None)\n","   \n","  emotion_model.save(model_path)\n","\n","else:\n","\n","  # returns a compiled model\n","  # identical to the previous one\n","  emorion_model = load_model(model_path, compile=True)"],"metadata":{"id":"mTvZqzPHj17b"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"rGjhowiWl1FI"},"execution_count":null,"outputs":[]}]}